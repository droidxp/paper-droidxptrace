\section{Introduction}\label{sec:introduction}

Almost two-thirds of the world use mobile technologies, such as smartphones and tablets, acquired a central role in everyday life in the last decade~\cite{Comscore}\cite{DBLP:journals/tse/MartinSJZH17}. In this context, Android Operation System has dominated this market, with around 150 billions of Android application~\footnote{In this paper, we will use the terms Android Applications, Android Apps and Apps interchangeably, to refer to Android software applications} (apps) downloaded by October 2018 \kn{Do we have something more new} from its marketplaces (Google Play)~\cite{Statista}. Due to this growing popularity, we witnessed an unprecedented growth of  Android apps that perform malicious activities (malware).  This inturn has made security issues in Android apps a relevant research topic. Several techniques have emerged to identify malicious behavior and vulnerabilities in Android apps, such as static analysis algorithms to expose private information leaks~\cite{DBLP:conf/pldi/ArztRFBBKTOM14}, or reveal misuse of 
cryptographic primitives.~\cite{DBLP:journals/tse/KrugerSABM21}

Another alternative for protection from Android malicious behavior consists in the use of dynamic analysis to mine Android sandboxes~\cite{DBLP:conf/icse/JamrozikSZ16}. Such approaches use automated testing tools (i.e., dynamic analysis) to explore apps behavior in terms of access to sensitive resources. A particularly popular way of creating malware is to injecstart with a benign version of an app from an official app store such as Google Play and inject it with code performing malicious activities such as broadcasting credit card information to a private server (\kn{Here add a citation that shows prevalence of repackaged malware}). The state of the art in terms of accuracy in detecting such malware is DroidBot~\cite{DBLP:conf/icse/LiYGC17} which has an accuracy rate of X\%. But their evaluation was performed on a set of $102$ app pairs~\footnote{App pairs here refers to pairs of the same app containing a benign and a malicious repackaged version}. Our internal analysis also revealed that the similarity index between the app pairs used in DroidBot's evaluation was $77\%$. Previous studies from David Lo et al.~\cite{DBLP:conf/wcre/BaoLL18} has revealed that malwares tend to be harder to detect if the similarity index is lower. Both the above mentioned points indicate that the relatively high accuracy reported in earlier evaluations of state of the art mining sandbox approaches may not scale to larger datasets with a more diverse and potentially higher similarity index.

In this paper, we address two open questions that arise. First, we seek to understand what the accuracy of the state of the art in mining sandbox approaches, DroidBot is when presented with a larger dataset ($800$ as opposed to the $102$). This new dataset also has a combined average similarity index of $Y\%$ which is lower than the original $77\%$. Secondly, if the accurary rate has indeed significantly dropped during the reproduction of DroidBot with a more real-world representative dataset what approaches can improve upon the accuracy. 

To answer the first question, we present the results of a study, where we observed the reults of DroidBot on a set from $800$ real apps pairs (benign/malicious). 
 For this reproduction study, we take advantage of DroidXP~\cite{DBLP:conf/scam/CostaMCMVBC20}, a tool suite that supported us not only to integrate DroidBot but also in our study setup and data collection.

To answer the second question, we hypothesize that mining sandbox approaches such as DroidBot perform a superficial analysis of differences between app pairs, i.e., only the difference in the set of sensitive APIs called. We assert that there are two major blindspots in the state of the art:
\begin{enumerate}
    \item The differences between two apps that call the same set of sensitive APIs, but differ in their dynamic call traces between the app's entry point and the sensitive APIs.
    \item The differences in the requested permissions between the two variant of apps.
\end{enumerate}

To this end, we used an auxiliary tool from DroidXP project called DroidXPTrace to compare all traces from an entry point to sensitive APIs call and checking if they are divergences. To observe the differences in the manifest files we harness the standard apk analysis tool from Android~\cite{au2011short}. 

In particular, we investigated the following specific questions in our study: (answered in Section~\ref{sec:results}):

\begin{enumerate}[(RQ1)]
 \item How well does the state of the art in mining sandbox approaches, DroidBot perform with a large dataet of app pairs with a diverse similarity index?
 \item Numerically, how relevant is a dynamic call trace analysis to improving malware detection in support of the mine sandbox approach?
 \item Numerically, how relevant is a manifest files analysis to improving malware detection in support of the mine sandbox approach?
\end{enumerate}
 

Our findings indicate that the accuracy of DroidBot significantly drops (to $Z\%$) when reproduced on a larger dataset of $800$ app pairs with a similarity index of $53.3\%$. Our experiments also reveal that the accuracy of sandbox approaches improve when they are made aware of the differences in the dynamic call trace and difference in permissions requested using the manifest file. Specifically, ... \kn{Please add here the results of path analysis and manifest files individually and their intersection}
During our analysis we also observed another interesting insight that out of the 162 sensitive APIs explored, just xx (xx\%) was injected at most repackage apps. It indicates that we have a small set of sensitive APIs used generally by malicious developers, pointing out that researchers can concentrate their effort on this specific set of sensitive APIs to improve the security of Android apps. 
In summary, this paper makes the following contributions:

\begin{enumerate}[1.]
\item A reproduction of the state of the art in mining sandbox approaches, Droidbot scaled in terms of number of app pairs and similarity index.
\item A broad comprehension about the role of trace analysis and static analysis on Android manifest file in improving the accuracy Android sandbox approach.
\item A in depth look into the kind of sensitive APIs that plague most repackaged apps.
\item A reproduction package of the studies online. Scripts for statistic analysis are also available.\footnote{https://github.com/droidxp/paper-droidxp-replication.git}
\end{enumerate}


The rest of the paper is organized as follows.....\kn{Here, please describe each section in one sentence}




