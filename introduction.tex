\section{Introduction}\label{sec:introduction}

Mobile technologies like smartphones and tablets have become fundamental to the way we function as a society. Almost two-thirds of the world population
uses mobile technologies~\cite{Comscore,DBLP:journals/tse/MartinSJZH17}, with the
Android Platform dominating this market and accounting for more than 70\% of the \emph{mobile
market share}, with almost 2.5 million Android applications~\footnote{In this paper, we will use the terms Android Applications, Android Apps, and Apps interchangeably, to refer to Android software applications} (apps)
available on the Google Play Store, in June 2023~\cite{Statista}.  
As popularity rises, so does the risk of potential attacks, prompting collaborative efforts from both academia and industry to design and develop new techniques for identifying malicious behavior or vulnerable code in Android apps~\cite{10.1145/3017427}.

For instance, one popular class of Android malware is based on repackaging apps~\cite{DBLP:conf/wcre/BaoLL18,le2018towards} where a benign
version of an app is
%such as Google Play, 
infected with malicious code, e.g., to broadcast
sensitive information to a private server~\cite{DBLP:journals/tse/LiBK21}, and subsequently shared
with users using even official app stores. The Mining Android Sandbox approach (\mas) was initially designed to construct sandboxes based on exploratory calls to sensitive APIs~\cite{DBLP:conf/icse/JamrozikSZ16}. However, it has also proven effective in detecting Android repackaged malware. The \mas operates in two distinct phases. In the first phase (exploratory phase), it utilizes automated test case generation tools to abstract the behavior of an app, focusing on calls to sensitive APIs (Application Programming Interfaces). Subsequently, duringthe normal executions of the app, the generated sandbox blocks any calls to sensitive APIs not observed during the exploratory phase.

Prior studies~\cite{DBLP:conf/wcre/BaoLL18,DBLP:journals/jss/CostaMMSSBNR22} have investigated the application of the MAS approach in detecting potential malicious behavior in repackaged apps. These studies have also conducted comparisons of the approach's performance by employing different test case generation tools during the exploratory phase, including Monkey~\cite{Monkey}, DroidBot~\cite{DBLP:conf/icse/LiYGC17}, and Droidmate~\cite{DBLP:conf/kbse/BorgesHZ18}.
These studies provide evidence that DroidBot surpasses other test generation tools, uncovering a larger number of potential malicious behaviors.
But these previous studies have two main limitations.
First, they use a small dataset of malware comprising only \appsSmall pairs of original/repackaged versions of an app---compromising external validity. Second, their assessments do not investigate
the impact of relevant features of the repackaged apps on the accuracy of the \mas for malware classification, including
(a) whether or not the repackaged version is a malware, (b) the similarity between the original and the repackaged versions of an app,
and (c) the malware family (e.g., \fm{gappusin}, \fm{kuguo}, \fm{dowgin}, etc.) when the repackaged
version of an app is a malware. This limitations compromise a full understanding of the \mas performance. We present more details about the \mas and related work in Section~\ref{sec:background}.

%{\bf MM: The second part of the last sentence is not clear. Are similarity and malware family two different "malware characteristics"?}

%In this paper, we present the results of an investigation that aims to replicate previous studies~\cite{DBLP:conf/wcre/BaoLL18,DBLP:conf/scam/CostaMCMVBC20} in a larger dataset of app pairs (original/repackaged versions), and then explore whether a more diverse sample of app pairs has an influence on the accuracy of the \mas for malware identification. To this end, we explore the performance of the \mas using a larger dataset we curated for this research and DroidBot~\cite{DBLP:conf/icse/LiYGC17} as test case generation---the tool that, according to the literature, leads to the most accuracy Android sandbox. Our new dataset is an order of magnitude larger (it contains \apps pairs of original/repackaged apps), comprises a much more diverse similarity index, and covers a broader range of malware families. 

To understand the impact of these issues on results already published in the literature, in this paper we reconsider the accuracy of the \mas based on
DroidBot~\cite{DBLP:conf/icse/LiYGC17}---as we mentioned, the test case generation tool that, according to the literature, leads to the most accurate Android sandbox, regarding malware identification. 
Compared to previous studies~\cite{DBLP:conf/wcre/BaoLL18,DBLP:conf/scam/CostaMCMVBC20},
we use a curated dataset of app pairs (original/repackaged versions) that is, in terms of magnitude, larger than the previously used
dataset (it contains \apps pairs of original/repackaged apps). We detail our datasets and the procedures we follow for data collection and data analysis in Section~\ref{sec:experimentalSetup}.
 
{\bf Negative results.} Our study reveals a significantly lower
accuracy (\fone of \fscore) of the \mas in comparison to what has been reported before (\fone of \fscoreSmall). 
Since an accuracy of \fscore is clearly unsatisfactory for a trustworthy malware classification technique, we conduct a set of experiments 
to understand the reasons for the lower accuracy in our larger dataset.
Our further assessments reveal that the \mas fails to correctly classify most of the samples from
the \gps malware family (a particular class of adware that frequently appears in repackaged apps). 
Out of the total of \appsGps samples within this family in our large dataset, the \mas failed to correctly classify \appsGpsFN samples as malware.
%(false negative).
Accordingly, the \gps family is responsible for substantially reducing the recall of the \mas. We detail the results of our experiments in Section~\ref{sec:results}. %, from $0.89$ to {\color{red}$0.52$}.

\review{In this paper we also investigate two extensions for the vanilla \mas, which consider additional information for classifying a repackaged version of an app as a malware: (a) the traces from entry points to the calls to sensitive APIs and (b) the value of the actual parameters in sensitive API method calls. We detail these extensions in Section~\ref{sec:complementary}. However, integrating both extensions lead to a slight improvement on the \mas accuracy (\fone ranges from 0.60 to 0.65). We discuss the implications and possible threads to the validity of our study in Section~\ref{sec:discussion} and present some final remarks in Section~\ref{sec:conclusions}. 
The main artifacts we produced during this research are available in the paper repository.}

\begin{small}
  \begin{center}
    \url{https://github.com/droidxp/paper-droidxptrace-results}
  \end{center}
\end{small}

