\section{Related Work}\label{sec:relatedwork}
In this section, we discuss prior studies in two areas: Dynamic and Static Analysis on Android and mine Sandbox.

\subsection{Dynamic and Static Analysis on Android}\label{sec:analysis}

Dynamic and Static Analysis on Android Apps are important practices for developing security apps. There is a large body of work on both analysis for Android apps security. 

Several approaches for malware detection, based on sensitive methods call and permission control Android apps~\cite{DBLP:conf/mobicom/WeiGNF12,DBLP:conf/asiajcis/WuMWLW12,DBLP:conf/sp/LiDLDG21}. Cai et al.~\cite{DBLP:journals/tse/CaiR21} presented a longitudinal study on Android apps focusing on run-time behaviors. However, this work does not explore specifically on malware detection, since only benign apps were considered in their study, and just presented possible security gaps. Fangfang et al.~\cite{DBLP:conf/wisec/ZhangHZW014} proposed ViewDroid, which models the UIs (user interface) of Android apps as a directed graph. ViewDroid identify apps repackaging, comparing graphs structures in app pairs (benign/malicious).

Through static analysis on Android Manifest files, Kim et al. proposed RomaDroid~\cite{DBLP:journals/access/KimLCP19}, a repackage Android app detector based on Manifest file. They proposed that Manifest file apps could be represented as a tree-based structure and also by a single string from this structure. Hence, RomaDroid compares the strings of the benign and malicious app, using the longest common subsequence algorithm (LCS). Au el al.~\cite{DBLP:conf/ccs/AuZHL12} also used static analysis on Android Manifest files to detect vulnerabilities in Android apps. They mapped Android APIs sensitive calls and your respective required permissions.

A relevant prior work ~\cite{DBLP:journals/tifs/0029LBKTLC17} done by Li et al. provided a systematized knowledge
on Android app security to the community. They conducted an empirical study comparing malicious repackage app with their benign counterparts (1,497 app pairs). They found that the majority of Android malware are nothing but repackaged versions of benign apps, that are done with no sophisticated way, many times automatically and using library code.

There are other works that focus on comparison of app code, and try to check similarity to detect repackaged apps. Following this approach, Crussell et al.~\cite{DBLP:conf/esorics/CrussellGC12} proposed  DNADroid, which compares program dependence graphs, and Zhou et al.~\cite{DBLP:conf/codaspy/ZhouZJN12} DroidMoss which detect and analyze repackaged apps adopting a fuzzy hashing technique.

\subsection{Mine Sandbox}\label{sec:mineSandbox}

The technique called mine sandbox consists of explores software behavior by means of automatic test generation tools and, thus, prevent Android apps from suspicious behaviors. Using a test generation tool named Droidmate~\cite{DBLP:conf/icse/JamrozikZ16}, Jamrozik et al.~\cite{DBLP:conf/icse/JamrozikSZ16} proposed the first mine Sandbox approach for Android environment, called Boxmate. 

Boxmate records the occurrences of calls to sensitive APIs and the event that trigger this call, like button click. Thus, Boxmate records events associated with each sensitive call in tuples (event, API). Jamrozik et al. present that using this finer granularity they have low false alarm rate, even when checking Boxmate against apps that uses reflection API package (\textit{java.util.reflect}). Reflection API at runtime can modify behavior of classes, interfaces and methods, and it is quite commonly used at malicious app~\cite{DBLP:conf/issta/0029BOK16}. 

However, At this work, they did not consider malware to validate their approach, using just twelve benign apps. Beyond they do not regard all path analysis between entry point (event) and access to resource sensitive (call API), regarding just the begin and the end of path.

Bao et al.~\cite{DBLP:conf/wcre/BaoLL18} conducted an empirical study to investigate the effectiveness of mine sandboxes, exploring test generation tools, including Droidmate. The authors found that in general, the sandboxes constructed by test generator tools can detect more than $70$\% malicious apps in a dataset comprising $102$ pairs (benign/malicious). The study also presented that among 5 test generate tools used, DroidBot~\cite{DBLP:conf/icse/LiYGC17} constructed the sandbox more efficient to detect malware.

Bao et al. do not investigate the effectiveness of mine sandboxes considering parameter values in the called APIs to compose the sandbox. To mitigate this issue, Le et al.~\cite{le2018towards} extend the previous work, combining more categories of APIs, and now considering parameters.

Neither of the studies in ~\cite{DBLP:conf/icse/JamrozikSZ16}~\cite{DBLP:conf/wcre/BaoLL18}~\cite{le2018towards} investigated the possibility of Path Analysis using call Graph complements mine sandbox technique, in terms of malware detection. They also do not considered the possibility of a static analysis on Manifest file apps, complement mine sandbox at same objective. Hence, our work although closely to aforementioned studies, differs from them in three aspects: First, these approaches used a little sample of app pairs. To improve the study, we conducted our work exploring $824$ pair apps and also included another test generator tool for Android, did not used at Bao et al. study, Humanoid~\cite{DBLP:conf/kbse/LiY0C19}---actually a DroidBot evolution. Second, we explore dynamic call graphs, exploring traces of apps version (benign/malicious) from entry point to sensitive API access, adding information about call graphs at our study. Third, we also consider explore suspicious features extract from Manifest file apps using static analysis.