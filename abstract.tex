\begin{abstract}
Android is the most popular operating system for the mobile platform, and smartphonesâ€™ ubiquitous nature in our daily lives has only made their security an important topic for researchers and practitioners alike. Previous research results have advocated using the Mining Android Sandbox Approach (\mas) to identify malicious behavior in repackaged apps, one of the most popular methods to inject malicious behavior into android apps. Nonetheless, these previous studies have drawn their conclusions using a small dataset of \appsSmall pairs of original and repackaged apps, threatening the findings w.r.t. external validity and opening the question of whether or not the MAS approach scales to larger and more diverse datasets. To mitigate these issues, we conduct a new experiment that reproduces the state-of-the-art research that empirically evaluated the MAS approach performance. Our reproduction study uses a dataset that is an order of magnitude larger than the datasets used in previous research (a total of \apps pairs of apps with a much diverse distribution of malware families, for instance). To our surprise, our experiments revealed that the accuracy rate of the \mas for malware identification drops significantly: $F_1$ score drops from \fscoreSmall in the previous dataset to \fscore in our larger dataset. After an in-depth assessment, we found that the representative number of malware from the \gps family explains the higher number of samples for which the \mas fails to correctly classify as malware. Our findings open the discussion on the possible blindspots that plague the \mas and their accuracy issues when scaled and reveal the need for complementing the \mas with other techniques so that it could effectively detect a broader class of malware. 
\end{abstract}

\begin{IEEEkeywords}
  Android Malware Detection, Dynamic Analysis, Mining Android Sandboxes
\end{IEEEkeywords}
