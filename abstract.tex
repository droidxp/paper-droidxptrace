\begin{abstract}

Android is by far the most popular operating system for the mobile platform and the ubiquitous nature of smartphones in our daily lives has only made its security a significant topic for researchers and practitioners alike. Previous research has shown that security experts can benefit from the mining sandbox approach to classify malware. Even though, state of the art in mining sandbox approaches, DroidBot reports a high accuracy rate of ~$70\%$, our investigation revealed that this accuracy is only valid on a smaller dataset of $102$ app pairs (benign-malicious). The dataset used in previous studies also contained only app pairs that were extremely similar (with an average similarity index of $77\%$). To understand whether mining sandbox approaches scale, we reproduced the results in a larger (complete) dataset of $800$ app pairs with a much more diverse similarity index and covering a broader range of malware kinds. Our experiments revealed that the accuracy rate drops significantly to $25\%$.  In this paper, we open the discussion on the possible blindspots that plague mining sandbox approaches and their accuracy issues when scaled. To this end, we hypothesize the presence of two major blindspots with mining sandbox approaches; the divergent dynamic call traces and differences in manifest files between the two app versions. Our evaluation also show that when mining sandbox approaches are made aware of these two blindspots, the accuracy rate almost doubles, among other valuable insights for the research community.

\end{abstract}

