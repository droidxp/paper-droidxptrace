\begin{abstract}
  %Context
  Android is the most popular operating system for the mobile platform, and smartphones' ubiquitous nature in our daily
  lives has only made their security an important topic for researchers and practitioners alike.
  %Problem
  Repackaging is one of the most popular methods to inject malicious behavior into android apps. Previous research results have advocated using the Mining Android Sandbox Approach (\mas) to identify malicious behavior in repackaged apps.
  Nonetheless, these previous studies draw their conclusions using a small dataset, threatening the validity of the findings concerning external validity and opening the question of whether
  or not the \mas scales.
  %Research Method
  To investigate these issues, we curate a new experiment replicating the methodology that is similar to that one used in a state of the art research that empirically evaluated the \mas performance on a dataset with a higher order of magnitude than the datasets used in previous research.
  %Results
  To our surprise, our experiments revealed that the accuracy rate of the \mas for malware identification drops significantly: F-Score drops from 0.89 in the previous dataset to 0.42 in our large dataset.
  After an in-depth assessment, we find that the more significant number of malware from the gappusin family explains the higher number of samples for which the \mas fails to classify as malware correctly (false negative).
  Our findings open the discussion on the possible blindspots that plague the \mas and their accuracy issues when scaled. 
\end{abstract}

\begin{IEEEkeywords}
  Android Malware Detection, Dynamic Analysis, Mining Android Sandboxes
\end{IEEEkeywords}
