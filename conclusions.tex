%\section{Conclusions and Future Work}\label{sec:conclusions}
\section{Conclusions}\label{sec:conclusions}


To better understand the strengths and limitations of the \mas for repackaged malware detection, this paper reported the results of an empirical study that reproduces previous research works~\cite{DBLP:conf/wcre/BaoLL18,DBLP:journals/jss/CostaMMSSBNR22} using a larger and more diverse dataset---in comparison to the datasets used in previous research. To our surprise, compared to published results, the performance of the \mas drops significantly for our comprehensive dataset ($F_1$ score reduces from 0.89 in previous papers to 0.54 here). This result is partially explained by the high prevalence of a specific malware family (named \gps), whose samples are incorrectly classified by the \mas. We also report the results of a reverse engineering effort, whose goal was to understand the features from the \gps family that reduce the performance of the \mas for malware classification. Our reverse engineering effort revealed common changing patterns in the \gps repackaged versions of original apps, which mostly use reflection to download an external apk asset for handling advertisements without introducing additional calls to sensitive APIs. This type of change compromises the effectiveness of the \mas for malware identification. These negative results illustrate the current limitations of using the MAS approach for malware classification and suggest further research directions for integrating the MAS approach with other techniques for malware identification.

%Additionally, the low $F_1$ score is also driven by the reduced precision rate of the \mas in the \cds. The high number of false positives explains this low rate, and has a possible explanations, our imbalance dataset, since \vt labels few samples in the \cds as malware. We open discuss about the number of engines we must consider for \vt report a repackage as malware, since the stricter we were in this criterion, the precision of the \mas down.

