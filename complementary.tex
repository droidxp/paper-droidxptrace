\section{Complementary Techniques - Trace and Parameters Analysis as \mas support (\textcolor{blue}{All this section is new for TSE journal})}\label{sec:complementary}


%Our work, although closely related to previous studies, differs from them in several aspects.  First, our assessment is more comprehensive: instead of considering $102$ pairs of benign/malign apps, we execute our study considering \apps pairs of apps. We then investigate which characteristics of the malware samples in the large dataset explain the lower performance.
We expand our investigation by introducing two extensions to the \mas. The first extension leverages dynamic call graphs
to analyze the paths from entry points to calls made to sensitive APIs in both the original and repackaged versions of an application.
The second extension enhances the \mas by comparing the values of actual parameters used in the calls to sensitive APIs,
drawing inspiration from the work of Le et al.~\cite{le2018towards}. We conduct a series of experiments using our \cds,
employing three configurations of the \mas: (a) with the call-graph-based extension enabled,
(b) with the parameter-based extension enabled, and (c) with both extensions enabled.

\subsection{Call Graph Path Analysis}


Regarding the call graph path analysis, we first build the dynamic call graph that abstracts the execution
of each version (original/repackaged) of the apps in our dataset. Our goal is to compute two sets: the set $S_p1$ of
paths from the entry points to the calls to sensitive APIs that appear in the dynamic call graph
that we build while executing DroidBot either in the original (set $S_{p1}$) or repackaged (set $S_{p2}$) version
of an app. Whenever the set difference $S_{p2} - S_{p1}$ is nonempty, we classify the repackaged version  as
malware. Our hypothesis is that the path analysis might complement the \mas in the task of malware classification.

Figure~\ref{fig:callGraph} illustrates an example of paths that we compute from the original and
repackaged versions of the app \texttt{com.android.remotecontrolppt}.
For this particular app, the vanilla \mas does not classify the repackaged version as a
malware (the vanilla \mas execution outputs that both versions calls the same set of sensitive APIs).
In Figure~\ref{fig:maliciousTrace}, the original and repackaged versions call the same
sensitive method \texttt{getSubscriberid()}. This sensitive method returns the device's unique
subscriber ID, and requires the manifest file permission \texttt{READ\_PHONE\_STATE}, present in both app versions.
Note that the original app calls this method through two distinct paths (Path 01 and Path 02), which suggests an expected action from an app user.
However, besides the two original paths, the repackaged version includes a third path (Path 03), which contains as start node a method
that performs a stealth computation on a background thread, suggesting an action that might start without
user's awareness.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.30]{images/maliciousCallGraph.pdf}
\caption{Illustrative example of the path analysis. In this case, both versions call the same set of sensitive APIs. Nonetheless,
the paths between the entry points and the calls to sensitive APIs diverge.}
 \label{fig:callGraph}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.28]{images/maliciousTrace_example01.pdf}
\caption{Example of suspect path.}
 \label{fig:maliciousTrace}
\end{figure}

Given the understanding that a malicious repackaged variant of an app
might include the same set of calls to sensitive APIs of the original version, though with additional
paths, we execute our experiments for all app pairs in our \cds, and check if this extension can
improve the accuracy of the \mas for malware classification. 
The results of our investigation reveal that the path analysis slightly reduces the number of false negatives---from $1,450$ to $1,327$,
with the side effect of increasing the number of false positives (from $252$ to $253$). We show these
results in the first and third rows of Table~\ref{tab:accuracyParameter}). In the end, the path analysis extension
improves the accuracy ($F_1$) of the \mas from $0.39$ to $0.45$, when compared with vanilla \mas.


\subsection{Parameter Analysis}

As described at~\cite{le2018towards}, malicious apps may require external data, like a remote server address to push an advertisement, or sink sensitive information to another location, different from the original, using SMS message for example. For this purpose, malicious apps may insert parameter in sensitive APIs, different from the original app. Thus, we also hypothesize that differences on the parameter (from both app versions), passed to the same sensitive APIS, may provides hints for suspicious repackaged apps. Figure~\ref{fig:parameterDiff} presents a real example of different parameters inserted at the same method, also extracted from our dataset \textbf{[com.nla.downloader]}. This example just use a \textit{java.net.URL} object to present a different advertising from the original app. Although not expressly harmful, repackaged apps may use objects from this \textit{Class} to download and run external files from a network in the infected system\cite{DBLP:journals/compsec/ObaidatSPP22}.

When we explore parameter analysis, we reduce the number of false negatives from $1450$ (vanilla \mas) to $1339$ samples, with the side effect of increasing the number of false positives from $252$ to $271$ (see the first and second row of Table~\ref{tab:accuracyParameter}).
In general, the accuracy ($F_1$) of the \mas using Parameter Analysis improves from 0.39 to 0.44 at \cds.



\begin{figure*}[t]
\centering
\includegraphics[scale=0.3]{images/parameterDiff.pdf}
\caption{Example of different parameters inserted at the same method.}
 \label{fig:parameterDiff}
\end{figure*}

\begin{table*}[ht]
  \caption{Accuracy of the \mas with aid of complementary techniques (3,211 app pairs).}
\centering{
  \begin{tabular}{lrrrrrr} \hline
    Dataset & TP   & FP  & FN  & Precision & Recall & $F_1$ \\ \hline
    
    %\mas + Traces  & \sds (102)   & 67   & 18  & 2   & 0.78      & 0.97   & 0.87  \\
    \cds \mas    & 545  & 252 & 1,450 & 0.68       & 0.27   & 0.39  \\
    \cds \mas + Trace     & 668  & 253 & 1,327 & 0.72       & 0.33   & 0.45  \\
    \cds \mas + Parameter     & 656  & 271 & 1,339 & 0.7       & 0.32   & 0.44  \\
    \cds \mas + Trace + Parameter     & 752  & 272 & 1,243 & 0.73       & 0.37   & 0.49  \\
    %\mas + Traces  & \cds (1203)   & 214  & 326 & 245 & 0.39      & 0.46   & 0.42  \\ 
    \hline
  \end{tabular}
  }
  \label{tab:accuracyParameter}
\end{table*}

\subsection{Combining trace and parameter analysis}

Additionally, we investigate if we could benefit from combining both techniques. When combining parameter and trace Analysis, we were able to detect $752$ (TP) of the repackaged apps ($23.41$\%). We reduce the number of FN from $1,450$ to $1,243$, however increasing the number of FP from $252$ to $272$. The combination of both techniques shows to be more effective than the vanilla \mas, or when we used just one of the techniques. In summary, the results of our studies reveal that the combination of both techniques present a ($F_1$) of $0.49$, as also reported in Table~\ref{tab:accuracyParameter}, improving the vanilla \mas.

\tb{5}{When combining both techniques, we reduces the number of false negatives (in comparison with the vanilla \mas), with the side effect of increasing the number of false positives. However, it improves the
overall accuracy ($F_1$) of \mas at malware detection, from 0.39\% to 0.49\% at \cds.} 
